{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "import yaml\n",
    "\n",
    "os.chdir('/home/gptrapletti/ds/satellite-multiclass-segm')\n",
    "\n",
    "with open('config.yaml') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> FUNCTION TO TURN MASK PNGS TO SEMANTIC MASK ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = sorted([os.path.join('data/images', filename) for filename in os.listdir(os.path.join('data/images'))])\n",
    "mask_filepaths = sorted([os.path.join('data/masks', filename) for filename in os.listdir(os.path.join('data/masks'))])\n",
    "\n",
    "len(image_filepaths), len(mask_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(mask_filepaths[55])\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_colors = {\n",
    "'background': [(112, 150, 146),\n",
    "  (2, 135, 115),\n",
    "  (9, 143, 150),\n",
    "  (0, 0, 0),\n",
    "  (119, 11, 32),\n",
    "  (102, 51, 0),\n",
    "  (255, 0, 0),\n",
    "  (190, 153, 153),\n",
    "  (0, 50, 89),\n",
    "  (153, 153, 153)],\n",
    " 'ground': [(128, 64, 128), (112, 103, 87), (130, 76, 0), (48, 41, 30)],\n",
    " 'vegetation': [(0, 102, 0), (107, 142, 35), (51, 51, 0), (190, 250, 190)],\n",
    " 'buildings': [(70, 70, 70), (102, 102, 156), (254, 228, 12), (254, 148, 12)],\n",
    " 'water': [(28, 42, 168)],\n",
    " 'person': [(255, 22, 96)]}\n",
    "\n",
    "category_ids = {\n",
    "    'background': 0,\n",
    "    'ground': 1,\n",
    "    'vegetation': 2,\n",
    "    'buildings': 3,\n",
    "    'water': 4,\n",
    "    'person': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.all(mask == [128, 64, 128], axis=2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in category_colors:\n",
    "    for color in category_colors[category]:\n",
    "        color_is_present = np.all(mask == color, axis=2)\n",
    "        mask[color_is_present] = category_ids[category]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(mask[..., 1] == mask[..., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IF DATALOADER'S NUM_WORKERS MAY HELP INSTEAD OF USING LIBRARY MULTIPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import from_png_to_semantic_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mask_filepaths):\n",
    "        super().__init__()\n",
    "        self.mask_filepaths = mask_filepaths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mask_filepaths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        mask_filepath = self.mask_filepaths[idx]\n",
    "        mask = cv2.imread(mask_filepath)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        semantic_mask = from_png_to_semantic_mask(mask)\n",
    "        return semantic_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(mask_filepaths=mask_filepaths[:10])\n",
    "\n",
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(dataloader):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <INS> FIND OUT IF DATASET CAN RETURN SINGLE PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It doesn't work this way\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = list(range(1, 10+1))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number = self.data[index]\n",
    "        for i in range(1, 5+1):\n",
    "            patch = number + i/10\n",
    "            return patch\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)*10\n",
    "    \n",
    "dataset = DummyDataset()\n",
    "\n",
    "mylist = list(dataset)\n",
    "\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To simulate computing bounding boxes coordinates before hand and then return a single patch\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = list(range(1, 10+1))\n",
    "        self.bounding_boxes = self.get_elements(self.data) \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.bounding_boxes[index]\n",
    "            \n",
    "    def get_elements(self, data):\n",
    "        l = []\n",
    "        for d in data:\n",
    "            for i in range(1, 5+1):\n",
    "                l.append(d + i/10)\n",
    "        \n",
    "        return l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "dataset = DummyDataset()\n",
    "\n",
    "mylist = list(dataset)\n",
    "\n",
    "mylist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with the satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = sorted([os.path.join('data/images', filename) for filename in os.listdir(os.path.join('data/images'))])\n",
    "mask_filepaths = sorted([os.path.join('data/masks', filename) for filename in os.listdir(os.path.join('data/masks'))])\n",
    "\n",
    "len(image_filepaths), len(mask_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.rand((3, 1500, 2000))\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_bbox(side, max_height, max_width):\n",
    "    top_left = random.randint(0, max_height - side), random.randint(0, max_width - side)\n",
    "    bottom_right = top_left[0] + side, top_left[1] + side\n",
    "    return (top_left, bottom_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow! For every patch the image is loaded again\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_filepaths,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.n_patch_per_image = 100\n",
    "        self.patch_bboxs = self.generate_patch_bboxs()\n",
    "           \n",
    "    def get_random_bbox(self, side, max_height, max_width):\n",
    "        top_left = random.randint(0, max_height - side), random.randint(0, max_width - side)\n",
    "        bottom_right = top_left[0] + side, top_left[1] + side\n",
    "        return (top_left, bottom_right)\n",
    "    \n",
    "    def generate_patch_bboxs(self):\n",
    "        patch_bboxs = []\n",
    "        for i in range(len(self.image_filepaths)):\n",
    "            for j in range(self.n_patch_per_image):\n",
    "                filepath = image_filepaths[i]\n",
    "                bbox = self.get_random_bbox(side=256, max_height=2000, max_width=3000)\n",
    "                patch_bboxs.append((filepath, bbox))\n",
    "        \n",
    "        return patch_bboxs\n",
    "                \n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.patch_bboxs[idx][0]\n",
    "        bbox = self.patch_bboxs[idx][1]\n",
    "        image = cv2.imread(filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (3000, 2000)) # cv2 wants tuple (width, height)\n",
    "        patch = image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "        return patch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patch_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(image_filepaths=image_filepaths[:300])\n",
    "len(dataset.patch_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(dataset)-1)\n",
    "a = dataset[idx]\n",
    "print(idx, a.shape)\n",
    "\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    patch = dataset[i]\n",
    "    \n",
    "# 2h 45min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached version\n",
    "from collections import OrderedDict\n",
    "\n",
    "class MyCachedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_filepaths, cache_size=10):\n",
    "        super().__init__()\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.n_patch_per_image = 100\n",
    "        self.patch_bboxs = self.generate_patch_bboxs()\n",
    "        self.cache_size = cache_size\n",
    "        self.image_cache = OrderedDict()\n",
    "\n",
    "    def get_random_bbox(self, side, max_height, max_width):\n",
    "        top_left = random.randint(0, max_height - side), random.randint(0, max_width - side)\n",
    "        bottom_right = top_left[0] + side, top_left[1] + side\n",
    "        return (top_left, bottom_right)\n",
    "    \n",
    "    def generate_patch_bboxs(self):\n",
    "        patch_bboxs = []\n",
    "        for i in range(len(self.image_filepaths)):\n",
    "            for j in range(self.n_patch_per_image):\n",
    "                filepath = image_filepaths[i]\n",
    "                bbox = self.get_random_bbox(side=256, max_height=2000, max_width=3000)\n",
    "                patch_bboxs.append((filepath, bbox))\n",
    "        \n",
    "        return patch_bboxs\n",
    "\n",
    "    def load_and_process_image(self, filepath):\n",
    "        if filepath in self.image_cache:\n",
    "            # Return cached image if it's in the cache\n",
    "            image = self.image_cache[filepath]\n",
    "            # Move the accessed entry to the end (to show it's recently used)\n",
    "            self.image_cache.move_to_end(filepath)\n",
    "        else:\n",
    "            image = cv2.imread(filepath)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (3000, 2000))\n",
    "            \n",
    "            # Add the loaded image to the cache\n",
    "            self.image_cache[filepath] = image\n",
    "            \n",
    "            # If cache exceeds size limit, remove the least recently used item (first item)\n",
    "            if len(self.image_cache) > self.cache_size:\n",
    "                self.image_cache.popitem(last=False)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.patch_bboxs[idx][0]\n",
    "        bbox = self.patch_bboxs[idx][1]\n",
    "        image = self.load_and_process_image(filepath)\n",
    "        patch = image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "        return patch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.patch_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyCachedDataset(image_filepaths=image_filepaths[:300])\n",
    "len(dataset.patch_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    patch = dataset[i]\n",
    "    \n",
    "# cached = 1m40s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> GRID SLICING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to find bounding box coordinates for patches extracting along a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = sorted([os.path.join('data/images', filename) for filename in os.listdir(os.path.join('data/images'))])\n",
    "mask_filepaths = sorted([os.path.join('data/masks', filename) for filename in os.listdir(os.path.join('data/masks'))])\n",
    "\n",
    "len(image_filepaths), len(mask_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(2000, 3000, 3)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 256\n",
    "overlap = 128\n",
    "max_height = 2000\n",
    "max_width = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 256\n",
    "overlap = 0.5\n",
    "max_height = 2000\n",
    "max_width = 3000\n",
    "\n",
    "increment = side - int(side*overlap)\n",
    "bboxs = []\n",
    "bbox_reference = ((0, 0), (256, 256))\n",
    "bboxs.append(bbox_reference)\n",
    "\n",
    "# While there is still space along the height\n",
    "while bboxs[-1][1][0] < max_height:\n",
    "    # While there is still space along the width\n",
    "    while max_width - bboxs[-1][1][1] > increment:\n",
    "        top_left = (bboxs[-1][0][0], bboxs[-1][0][1] + increment)\n",
    "        bottom_right = (bboxs[-1][1][0], bboxs[-1][1][1] + increment)\n",
    "        new_bbox = (top_left, bottom_right)\n",
    "        bboxs.append(new_bbox)\n",
    "    else:\n",
    "        # If last bbox along the width tells use there is still space for one more row along the height\n",
    "        if max_height - bboxs[-1][1][0] > increment:\n",
    "            # Start a new row\n",
    "            bbox_reference = ( (bbox_reference[0][0]+increment, bbox_reference[0][1]), (bbox_reference[1][0]+increment, bbox_reference[1][1]) )\n",
    "            bboxs.append(bbox_reference)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "len(bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image\n",
    "image = cv2.imread(image_filepaths[54])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (3000, 2000))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a patch\n",
    "bbox = bboxs[0]\n",
    "patch = image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "\n",
    "plt.imshow(patch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all patches\n",
    "n = 22\n",
    "loc = 0\n",
    "\n",
    "for i in range(int(len(bboxs)/n)):\n",
    "    fig, axs = plt.subplots(1, n, figsize=(20, 5))\n",
    "    for i in range(n):    \n",
    "        bbox = bboxs[loc]\n",
    "        axs[i].imshow(image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :])\n",
    "        axs[i].axis('off')\n",
    "        loc += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version where, if there is not space for another patch, a patch is cropped from the end of the image, going backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 256\n",
    "overlap = 0.50\n",
    "max_height = 2000\n",
    "max_width = 3000\n",
    "\n",
    "stride = side - int(side*overlap)\n",
    "n_bboxs_along_height = 1 + ((max_height - side) // stride)\n",
    "n_bboxs_along_width = 1 + ((max_width - side) // stride)\n",
    "print(n_bboxs_along_height, n_bboxs_along_width)\n",
    "\n",
    "bboxs = []\n",
    "bbox_reference = ((0, 0), (256, 256))\n",
    "bboxs.append(bbox_reference)\n",
    "\n",
    "for i in range(n_bboxs_along_height): ### ! +1 for the last row (manual)\n",
    "    \n",
    "    for j in range(n_bboxs_along_width -1): # -1?\n",
    "        top_left = (bboxs[-1][0][0], bboxs[-1][0][1] + stride)\n",
    "        bottom_right = (bboxs[-1][1][0], bboxs[-1][1][1] + stride)\n",
    "        new_bbox = (top_left, bottom_right)\n",
    "        bboxs.append(new_bbox)\n",
    "        \n",
    "    last_bbox = ( (bboxs[-1][0][0], max_width - side), (bboxs[-1][1][0], max_width) )\n",
    "    bboxs.append(last_bbox)\n",
    "       \n",
    "    bbox_reference = ( (bbox_reference[0][0]+stride, bbox_reference[0][1]), (bbox_reference[1][0]+stride, bbox_reference[1][1]) )\n",
    "    bboxs.append(bbox_reference)\n",
    "\n",
    "# Remove last boox for it is out of bounds.\n",
    "bboxs = bboxs[:-1] \n",
    "\n",
    "# Do last row (from the end of the height)\n",
    "bbox_start = ( (max_height - side, 0), (max_height, side) )\n",
    "bboxs.append(bbox_start)\n",
    "\n",
    "for j in range(n_bboxs_along_width -1):\n",
    "    top_left = (bboxs[-1][0][0], bboxs[-1][0][1] + stride)\n",
    "    bottom_right = (bboxs[-1][1][0], bboxs[-1][1][1] + stride)\n",
    "    new_bbox = (top_left, bottom_right)\n",
    "    bboxs.append(new_bbox)\n",
    "\n",
    "last_bbox = ( (bboxs[-1][0][0], max_width - side), (bboxs[-1][1][0], max_width) )\n",
    "bboxs.append(last_bbox)\n",
    "\n",
    "len(bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot patches\n",
    "n = 23\n",
    "loc = 0\n",
    "\n",
    "for i in range(n_bboxs_along_height + 1):\n",
    "    fig, axs = plt.subplots(1, n, figsize=(20, 5))\n",
    "    for i in range(n):    \n",
    "        bbox = bboxs[loc]\n",
    "        axs[i].imshow(image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :])\n",
    "        axs[i].axis('off')\n",
    "        loc += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually extract patches\n",
    "patches = []\n",
    "\n",
    "for bbox in tqdm(bboxs):\n",
    "    patch = image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "    patches.append(patch)\n",
    "    \n",
    "# Shape check\n",
    "print(set([patch.shape for patch in patches]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> PNG PARTIAL LOADING TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PIL.Image.open(image_filepaths[27]) as image:\n",
    "    patch = np.array(image.crop((100, 200, 300, 400)))\n",
    "    \n",
    "patch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> CHECK PATCH SIZE VS IMAGE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros(shape=(2000, 3000))\n",
    "bbox = bboxs[222]\n",
    "image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1]] = 1\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros(shape=(2000, 3000))\n",
    "n_patches = 28\n",
    "\n",
    "bboxs = [get_random_bbox(side=256, max_height=2000, max_width=3000) for i in range(n_patches)]\n",
    "\n",
    "for bbox in bboxs:\n",
    "    image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1]] = 1\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins> RANDOM PATCH WITHOUT OVERLAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to not return bboxs that overlap with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_random_bbox, shapely_friendly_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filepaths = sorted([os.path.join('data/images', filename) for filename in os.listdir(os.path.join('data/images'))])\n",
    "mask_filepaths = sorted([os.path.join('data/masks', filename) for filename in os.listdir(os.path.join('data/masks'))])\n",
    "\n",
    "len(image_filepaths), len(mask_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It works but every patch defines a cross upon which there can't be other patches.\n",
    "bboxs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    bbox_i = get_random_bbox(side=256, max_height=2000, max_width=3000)\n",
    "    if len(bboxs) == 0:\n",
    "        bboxs.append(bbox_i)\n",
    "    else:\n",
    "        checks = 0\n",
    "        for bbox in bboxs:\n",
    "            # Check if bbox_i is not overlapping\n",
    "            height_check = bbox_i[0][0] > bbox[1][0] or bbox_i[1][0] < bbox[0][0]\n",
    "            width_check = bbox_i[0][1] > bbox[1][1] or bbox_i[1][1] < bbox[0][1]\n",
    "            if height_check and width_check:\n",
    "                checks += 1\n",
    "        if checks == len(bboxs):\n",
    "            bboxs.append(bbox_i)\n",
    "                          \n",
    "print(len(bboxs))\n",
    "\n",
    "image = np.zeros(shape=(2000, 3000))\n",
    "\n",
    "for bbox in bboxs:\n",
    "    image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1]] = 1\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version with shapely\n",
    "bboxs = []\n",
    "\n",
    "for i in range(100):\n",
    "    bbox_i = get_random_bbox(side=256, max_height=2000, max_width=3000)\n",
    "    if len(bboxs) == 0:\n",
    "        bboxs.append(bbox_i)\n",
    "    else:\n",
    "        is_overlapping = False\n",
    "        bbox_i_polygon = Polygon(shapely_friendly_bbox(bbox_i))\n",
    "        for bbox in bboxs:\n",
    "            bbox_polygon = Polygon(shapely_friendly_bbox(bbox))\n",
    "            intersection = bbox_i_polygon.intersects(bbox_polygon)\n",
    "            if intersection:\n",
    "                is_overlapping = True\n",
    "                break\n",
    "        if not is_overlapping:\n",
    "            bboxs.append(bbox_i)\n",
    "\n",
    "                          \n",
    "print(len(bboxs))\n",
    "\n",
    "image = np.zeros(shape=(2000, 3000))\n",
    "\n",
    "for bbox in bboxs:\n",
    "    image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1]] = 1\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that given image height and width and desired number of bboxs, returns them.\n",
    "def generate_random_non_overlapping_bboxs(n_bboxs, side, max_height, max_width):\n",
    "    bboxs = []\n",
    "    while len(bboxs) != n_bboxs:\n",
    "        bbox_i = get_random_bbox(side=side, max_height=max_height, max_width=max_width)\n",
    "        if len(bboxs) == 0:\n",
    "            bboxs.append(bbox_i)\n",
    "        else:\n",
    "            is_overlapping = False\n",
    "            bbox_i_polygon = Polygon(shapely_friendly_bbox(bbox_i))\n",
    "            for bbox in bboxs:\n",
    "                bbox_polygon = Polygon(shapely_friendly_bbox(bbox))\n",
    "                intersection = bbox_i_polygon.intersects(bbox_polygon)\n",
    "                if intersection:\n",
    "                    is_overlapping = True\n",
    "                    break\n",
    "            if not is_overlapping:\n",
    "                bboxs.append(bbox_i)\n",
    "                \n",
    "    return bboxs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxs = generate_random_non_overlapping_bboxs(n_bboxs=28, side=256, max_height=2000, max_width=3000)\n",
    "\n",
    "print(len(bboxs))\n",
    "\n",
    "image = np.zeros(shape=(2000, 3000))\n",
    "\n",
    "for bbox in bboxs:\n",
    "    image[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1]] = 1\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how the number of iteractions in the while-loop scale on the basis of the number of bbboxs requested \n",
    "for n_bboxs in range(5, 65, 5):\n",
    "\n",
    "    bboxs = []\n",
    "    iteractions = 0\n",
    "    while len(bboxs) != n_bboxs:\n",
    "        iteractions += 1\n",
    "        bbox_i = get_random_bbox(side=256, max_height=2000, max_width=3000)\n",
    "        if len(bboxs) == 0:\n",
    "            bboxs.append(bbox_i)\n",
    "        else:\n",
    "            is_overlapping = False\n",
    "            bbox_i_polygon = Polygon(shapely_friendly_bbox(bbox_i))\n",
    "            for bbox in bboxs:\n",
    "                bbox_polygon = Polygon(shapely_friendly_bbox(bbox))\n",
    "                intersection = bbox_i_polygon.intersects(bbox_polygon)\n",
    "                if intersection:\n",
    "                    is_overlapping = True\n",
    "                    break\n",
    "            if not is_overlapping:\n",
    "                bboxs.append(bbox_i)\n",
    "                \n",
    "    print(n_bboxs, iteractions)\n",
    "    \n",
    "# (number of bbox, number of iteractions) (there is a certain variance though):\n",
    "# - 5 5\n",
    "# - 10 11\n",
    "# - 15 28\n",
    "# - 20 50\n",
    "# - 25 61\n",
    "# - 30 93\n",
    "# - 35 254\n",
    "# - 40 285\n",
    "# - 45 3585\n",
    "\n",
    "# Better to keep the number of bboxs per image under 30!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
