model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: checkpoints
  filename: '{epoch}'
  monitor: val_loss
  mode: min
  save_top_k: 1

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: epoch

log_grad_norm:
  _target_: src.callbacks.LogGradNormCallback

early_stopping:
  _target_: pytorch_lightning.callbacks.EarlyStopping
  monitor: val_loss
  mode: min
  min_delta: 1e-4
  patience: 15
